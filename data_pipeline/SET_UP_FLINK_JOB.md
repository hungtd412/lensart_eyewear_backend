# Windows PowerShell Commands Reference

**For Windows users - All commands work in PowerShell**

---

## ğŸ“‘ Menu - Table of Contents

### ğŸ¯ Quick Links
- [Quick Reference Card](#-quick-reference-card-windows) - Lá»‡nh nhanh cho daily operations
- [Deploy Jobs](#deploy-jobs-windows) - Triá»ƒn khai Flink jobs 
- [Common Issues](#-common-issues-on-windows) - Troubleshooting lá»—i thÆ°á»ng gáº·p

### ğŸ“š Full Documentation

1. **[ğŸ”§ Cancel All Flink Jobs](#-cancel-all-flink-jobs-windows)**
   - Há»§y táº¥t cáº£ Flink jobs (manual & automatic)

2. **[ğŸš€ Complete Windows Setup Commands](#-complete-windows-setup-commands)**
   - [Apply Final Schema](#apply-final-schema) - Táº¡o database schema
   - [Rebuild Flink Jobs](#rebuild-flink-jobs) - Build JAR vá»›i Maven
   - [Deploy Jobs](#deploy-jobs-windows) - Deploy Flink jobs (3 methods)
   - [Verify Jobs Running](#verify-jobs-running) - Kiá»ƒm tra job status

3. **[ğŸ§ª Testing Commands](#-testing-commands-windows)**
   - [Send Test Transactions](#send-test-transactions) - Gá»­i test data vÃ o Kafka
   - [Check Database](#check-database-windows) - Query PostgreSQL results

4. **[ğŸ”„ Daily Operations](#-daily-operations-windows)**
   - [Start Everything](#start-everything) - Khá»Ÿi Ä‘á»™ng services
   - [Stop Everything](#stop-everything) - Dá»«ng services
   - [Restart Just Flink Jobs](#restart-just-flink-jobs) - Restart jobs only

5. **[ğŸ“Š Monitoring Commands](#-monitoring-commands-windows)**
   - [Check Everything](#check-everything) - Kiá»ƒm tra containers, jobs, database
   - [View Logs](#view-logs) - Xem logs cá»§a tá»«ng service

6. **[ğŸ› Troubleshooting](#-troubleshooting-windows)**
   - [Reset Everything](#reset-everything) - Clear data vÃ  restart
   - [Check Kafka Messages](#check-kafka-messages) - Debug Kafka topics

7. **[ğŸ“‹ Quick Reference Card](#-quick-reference-card-windows)**
   - Táº¥t cáº£ lá»‡nh quan trá»ng trong má»™t chá»—

8. **[âš ï¸ Important Notes for Windows](#ï¸-important-notes-for-windows)**
   - LÆ°u Ã½ vá» PowerShell vÃ  Windows paths

9. **[ğŸ¯ Common Issues on Windows](#-common-issues-on-windows)**
   - [Directory not found in container](#issue-directory-not-found-in-container) â­ **Má»šI - Pháº£i táº¡o thÆ° má»¥c trÆ°á»›c**
   - [Docker tar writer error](#issue-docker-tar-writer-error--path-resolution-error) 
   - [Command not recognized](#issue-command-not-recognized)
   - [Path not found](#issue-path-not-found)
   - [Long commands](#issue-long-commands)

---

## ğŸ’¡ Workflow Khuyáº¿n Nghá»‹ (Recommended Workflow)

### ğŸš€ Láº§n Ä‘áº§u setup (First Time Setup)
```
1. Start Everything (ğŸ”„ Daily Operations)
2. Apply Final Schema (ğŸš€ Complete Setup)
3. Build Flink Jobs (ğŸš€ Complete Setup)
4. Deploy Jobs (ğŸš€ Complete Setup) - DÃ¹ng Method 1 vá»›i Resolve-Path
5. Verify Jobs Running (ğŸš€ Complete Setup)
6. Send Test Transactions (ğŸ§ª Testing)
7. Check Database (ğŸ§ª Testing)
```

### ğŸ”„ HÃ ng ngÃ y (Daily Usage)
```
1. Start Everything â†’ Wait 60s â†’ Check Status
2. Send transactions (tá»« Laravel API)
3. Monitor logs & database
4. Stop Everything khi xong viá»‡c
```

### ğŸ› Khi gáº·p lá»—i (When Errors Occur)
```
1. Check logs cá»§a service bá»‹ lá»—i (ğŸ“Š Monitoring)
2. TÃ¬m lá»—i trong Common Issues (ğŸ¯ Common Issues)
3. Thá»­ Reset Everything (ğŸ› Troubleshooting)
4. Rebuild & Redeploy náº¿u cáº§n
```

---

## ğŸ”§ Cancel All Flink Jobs (Windows)

### Method 1: Manual (Recommended for Windows)

```powershell
# 1. Liá»‡t kÃª táº¥t cáº£ jobs Ä‘ang cháº¡y (List all running jobs)
docker exec flink-jobmanager flink list -r

# 2. Copy cÃ¡c Job IDs tá»« output (Copy Job IDs from output)

# 3. Há»§y tá»«ng job má»™t cÃ¡ch thá»§ cÃ´ng (Cancel each job manually)
docker exec flink-jobmanager flink cancel <JOB_ID_1>
docker exec flink-jobmanager flink cancel <JOB_ID_2>
```

**Giáº£i thÃ­ch chi tiáº¿t:**
- `docker exec`: Thá»±c thi lá»‡nh bÃªn trong container Ä‘ang cháº¡y
- `flink-jobmanager`: TÃªn container quáº£n lÃ½ cÃ¡c Flink jobs
- `flink list -r`: List táº¥t cáº£ jobs Ä‘ang running (-r = running only)
- `flink cancel <JOB_ID>`: Há»§y job vá»›i ID cá»¥ thá»ƒ (graceful shutdown)
- Thay `<JOB_ID_1>` báº±ng ID thá»±c táº¿ tá»« output cá»§a lá»‡nh list

---

### Method 2: PowerShell Script (Tá»± Ä‘á»™ng há»§y táº¥t cáº£)

```powershell
# Láº¥y danh sÃ¡ch Job IDs vÃ  há»§y tá»± Ä‘á»™ng
# Get job IDs automatically and cancel them
$jobs = docker exec flink-jobmanager flink list -r | Select-String ":\s+(\w+)\s+:" | ForEach-Object { $_.Matches.Groups[1].Value }

foreach ($job in $jobs) {
    Write-Host "Canceling job: $job"
    docker exec flink-jobmanager flink cancel $job
}
```

**Giáº£i thÃ­ch chi tiáº¿t:**
- `docker exec ... flink list -r`: Láº¥y danh sÃ¡ch jobs Ä‘ang cháº¡y
- `Select-String ":\s+(\w+)\s+:"`: TÃ¬m pattern chá»©a Job ID (regex matching)
  - `\s+`: Má»™t hoáº·c nhiá»u khoáº£ng tráº¯ng
  - `(\w+)`: Capture group - chá»¯ vÃ  sá»‘ (Job ID)
- `ForEach-Object { $_.Matches.Groups[1].Value }`: Láº¥y giÃ¡ trá»‹ Job ID tá»« regex group
- `foreach ($job in $jobs)`: Loop qua tá»«ng Job ID
- `Write-Host`: In thÃ´ng bÃ¡o ra console
- `flink cancel $job`: Há»§y job vá»›i ID Ä‘Ã£ láº¥y Ä‘Æ°á»£c

---

## ğŸš€ Complete Windows Setup Commands

### Apply Final Schema

```powershell
# BÆ°á»›c 1: Copy file schema vÃ o container PostgreSQL
# Step 1: Copy schema file into PostgreSQL container
docker cp data_pipeline\docker\postgres\final_schema.sql postgres:/tmp/

# BÆ°á»›c 2: Thá»±c thi file SQL Ä‘á»ƒ táº¡o/cáº­p nháº­t database schema
# Step 2: Execute SQL file to create/update database schema
docker exec postgres psql -U postgres -d lensart_events -f /tmp/final_schema.sql
```

**Giáº£i thÃ­ch chi tiáº¿t tá»«ng cÃ¢u lá»‡nh:**

**Lá»‡nh 1:** `docker cp data_pipeline\docker\postgres\final_schema.sql postgres:/tmp/`
- `docker cp`: Copy file tá»« host vÃ o container (hoáº·c ngÆ°á»£c láº¡i)
- `data_pipeline\docker\postgres\final_schema.sql`: File SQL chá»©a schema (tables, indexes, views)
- `postgres:/tmp/`: Container tÃªn "postgres", thÆ° má»¥c Ä‘Ã­ch "/tmp/"
- **Má»¥c Ä‘Ã­ch**: ÄÆ°a file schema vÃ o container Ä‘á»ƒ PostgreSQL cÃ³ thá»ƒ Ä‘á»c

**Lá»‡nh 2:** `docker exec postgres psql -U postgres -d lensart_events -f /tmp/final_schema.sql`
- `docker exec postgres`: Cháº¡y lá»‡nh trong container "postgres"
- `psql`: PostgreSQL command-line client
- `-U postgres`: User name lÃ  "postgres" (admin user)
- `-d lensart_events`: Database name lÃ  "lensart_events"
- `-f /tmp/final_schema.sql`: File (file) SQL cáº§n thá»±c thi
- **Má»¥c Ä‘Ã­ch**: Cháº¡y cÃ¡c SQL commands Ä‘á»ƒ táº¡o báº£ng, indexes, views trong database

---

### Rebuild Flink Jobs

```powershell
# BÆ°á»›c 1: Di chuyá»ƒn vÃ o thÆ° má»¥c flink-jobs
# Step 1: Navigate to flink-jobs directory
cd data_pipeline\flink-jobs

# BÆ°á»›c 2: Build project vá»›i Maven
# Step 2: Build project with Maven
mvn clean package -DskipTests
```

**Giáº£i thÃ­ch chi tiáº¿t:**

**Lá»‡nh:** `mvn clean package -DskipTests`
- `mvn`: Maven command-line tool (build tool cho Java projects)
- `clean`: Maven lifecycle phase - xÃ³a thÆ° má»¥c `target/` cÅ©
  - Äáº£m báº£o build tá»« Ä‘áº§u, khÃ´ng cÃ³ file cÅ© cÃ²n sÃ³t láº¡i
- `package`: Maven lifecycle phase - compile vÃ  Ä‘Ã³ng gÃ³i thÃ nh JAR file
  - Táº¡o file `.jar` trong thÆ° má»¥c `target/`
- `-DskipTests`: Maven option - bá» qua viá»‡c cháº¡y unit tests
  - Tiáº¿t kiá»‡m thá»i gian khi build
  - Sá»­ dá»¥ng khi báº¡n cháº¯c cháº¯n code Ä‘Ã£ Ä‘Ãºng

**Output mong Ä‘á»£i:**
- File JAR sáº½ Ä‘Æ°á»£c táº¡o táº¡i: `data_pipeline\flink-jobs\target\lensart-sales-pipeline-1.0.0.jar`
- Maven sáº½ táº£i cÃ¡c dependencies cáº§n thiáº¿t (Flink, Kafka, PostgreSQL drivers)
- Build thÃ nh cÃ´ng khi tháº¥y: `BUILD SUCCESS`

**Khi nÃ o cáº§n rebuild:**
- Sau khi sá»­a code Java cá»§a Flink jobs
- Sau khi thay Ä‘á»•i dependencies trong `pom.xml`
- Khi cáº§n version JAR má»›i Ä‘á»ƒ deploy

---

### Deploy Jobs (Windows)

#### Method 1: Recommended - Direct Path (Khuyáº¿n nghá»‹)

```powershell
# BÆ°á»›c 1: Táº¡o thÆ° má»¥c usrlib trong container (náº¿u chÆ°a cÃ³)
# Step 1: Create usrlib directory in container (if not exists)
docker exec flink-jobmanager mkdir -p /opt/flink/usrlib

# BÆ°á»›c 2: Set Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i cá»§a file JAR
# Step 2: Set absolute path of JAR file
$jarPath = "D:\UIT\HK5\WebDevelopment\MyProject\LensArtEyewear\lensart_eyewear_backend\data_pipeline\flink-jobs\target\lensart-sales-pipeline-1.0.0.jar"

# BÆ°á»›c 3: Copy file JAR vÃ o container Flink
# Step 3: Copy JAR file into Flink container
docker cp $jarPath flink-jobmanager:/opt/flink/usrlib/lensart-sales-pipeline-1.0.0.jar

# Triá»ƒn khai Job 1: Xá»­ lÃ½ giao dá»‹ch bÃ¡n hÃ ng (Sales Transaction Processor)
# Deploy Job 1: Sales Transaction Processor
# - Äá»c events tá»« Kafka topic "order-created"
# - Chuyá»ƒn Ä‘á»•i vÃ  lÆ°u vÃ o báº£ng sales_transactions trong PostgreSQL
docker exec flink-jobmanager flink run -d -c com.lensart.pipeline.SalesTransactionJob /opt/flink/usrlib/lensart-sales-pipeline-1.0.0.jar

# Triá»ƒn khai Job 2: Tá»•ng há»£p doanh sá»‘ sáº£n pháº©m (Product Sales Aggregator)
# Deploy Job 2: Product Sales Aggregator
# - TÃ­nh tá»•ng doanh sá»‘ theo sáº£n pháº©m má»—i 5 phÃºt
# - LÆ°u káº¿t quáº£ vÃ o báº£ng product_sales
docker exec flink-jobmanager bash -c "export WINDOW_SIZE_MINUTES=5 && flink run -d -c com.lensart.pipeline.ProductSalesAggregatorJob /opt/flink/usrlib/lensart-sales-pipeline-1.0.0.jar"
```

**Giáº£i thÃ­ch chi tiáº¿t cÃ¡c tham sá»‘:**
- `mkdir -p /opt/flink/usrlib`: Táº¡o thÆ° má»¥c (náº¿u chÆ°a cÃ³), `-p` khÃ´ng bÃ¡o lá»—i náº¿u Ä‘Ã£ tá»“n táº¡i
- `$jarPath`: ÄÆ°á»ng dáº«n tuyá»‡t Ä‘á»‘i cá»§a file JAR (thay Ä‘á»•i theo workspace cá»§a báº¡n)
- `docker cp`: Copy file tá»« host vÃ o container
- `-d`: Cháº¡y job á»Ÿ cháº¿ Ä‘á»™ detached (cháº¡y ná»n)
- `-c`: Chá»‰ Ä‘á»‹nh class chÃ­nh (main class) cá»§a job
- `WINDOW_SIZE_MINUTES=5`: Thiáº¿t láº­p cá»­a sá»• thá»i gian 5 phÃºt cho aggregation

---

#### Method 2: Alternative - Navigate First (Äáº£m báº£o 100% khÃ´ng lá»—i path)

```powershell
# BÆ°á»›c 1: Táº¡o thÆ° má»¥c trong container
# Step 1: Create directory in container
docker exec flink-jobmanager mkdir -p /opt/flink/usrlib

# BÆ°á»›c 2: Di chuyá»ƒn Ä‘áº¿n thÆ° má»¥c chá»©a JAR file
# Step 2: Navigate to the directory containing JAR file
cd data_pipeline\flink-jobs\target

# BÆ°á»›c 3: Copy file JAR (khÃ´ng cáº§n path phá»©c táº¡p)
# Step 3: Copy JAR file (no complex path needed)
docker cp lensart-sales-pipeline-1.0.0.jar flink-jobmanager:/opt/flink/usrlib/

# BÆ°á»›c 4: Quay láº¡i thÆ° má»¥c gá»‘c
# Step 4: Return to root directory
cd ..\..\..

# BÆ°á»›c 5: Triá»ƒn khai cáº£ 2 jobs
# Step 5: Deploy both jobs
docker exec flink-jobmanager flink run -d -c com.lensart.pipeline.SalesTransactionJob /opt/flink/usrlib/lensart-sales-pipeline-1.0.0.jar
docker exec flink-jobmanager bash -c "export WINDOW_SIZE_SECONDS=2 && flink run -d -c com.lensart.pipeline.ProductSalesAggregatorJob /opt/flink/usrlib/lensart-sales-pipeline-1.0.0.jar"
```

**Ã nghÄ©a tá»«ng cÃ¢u lá»‡nh:**
1. `cd data_pipeline\flink-jobs\target`: Di chuyá»ƒn vÃ o thÆ° má»¥c chá»©a file JAR Ä‘Ã£ build
2. `docker cp`: Copy file tá»« mÃ¡y host vÃ o container Docker
3. `cd ..\..\..\`: Quay láº¡i thÆ° má»¥c gá»‘c cá»§a project (3 cáº¥p lÃªn)
4. `docker exec`: Thá»±c thi lá»‡nh bÃªn trong container Docker
5. `flink run -d`: Cháº¡y Flink job á»Ÿ cháº¿ Ä‘á»™ ná»n (detached mode)

---

#### Method 3: Single Command - One Liner (Cháº¡y táº¥t cáº£ trong 1 dÃ²ng)

```powershell
# Táº¡o thÆ° má»¥c, copy JAR vÃ  deploy cáº£ 2 jobs trong 1 lá»‡nh
docker exec flink-jobmanager mkdir -p /opt/flink/usrlib; docker cp "D:\UIT\HK5\WebDevelopment\MyProject\LensArtEyewear\lensart_eyewear_backend\data_pipeline\flink-jobs\target\lensart-sales-pipeline-1.0.0.jar" flink-jobmanager:/opt/flink/usrlib/lensart-sales-pipeline-1.0.0.jar; docker exec flink-jobmanager flink run -d -c com.lensart.pipeline.SalesTransactionJob /opt/flink/usrlib/lensart-sales-pipeline-1.0.0.jar; docker exec flink-jobmanager bash -c "export WINDOW_SIZE_MINUTES=5 && flink run -d -c com.lensart.pipeline.ProductSalesAggregatorJob /opt/flink/usrlib/lensart-sales-pipeline-1.0.0.jar"
```

**LÆ°u Ã½ quan trá»ng:**
- Thay Ä‘Æ°á»ng dáº«n JAR file theo workspace cá»§a báº¡n
- Dáº¥u `;` ngÄƒn cÃ¡ch cÃ¡c lá»‡nh trong PowerShell
- Náº¿u gáº·p lá»—i path, hÃ£y dÃ¹ng Method 2 (navigate first)

---

### Verify Jobs Running

```powershell
# Kiá»ƒm tra cÃ¡c Flink jobs Ä‘ang cháº¡y
# Check running Flink jobs
docker exec flink-jobmanager flink list -r
```

**Giáº£i thÃ­ch:**
- `flink list`: Liá»‡t kÃª táº¥t cáº£ Flink jobs
- `-r`: Chá»‰ hiá»ƒn thá»‹ jobs Ä‘ang RUNNING
- Output sáº½ hiá»ƒn thá»‹:
  - Job ID (UUID)
  - Job Name (SalesTransactionJob, ProductSalesAggregatorJob)
  - Status (RUNNING)
  - Start time

**Output vÃ­ dá»¥:**
```
------------------ Running/Restarting Jobs -------------------
22.11.2024 15:30:45 : abc123def456 : Sales Transaction Processor (RUNNING)
22.11.2024 15:30:50 : def789ghi012 : Product Sales Aggregator (RUNNING)
--------------------------------------------------------------
```

**Náº¿u khÃ´ng cÃ³ jobs nÃ o:**
- Sáº½ hiá»ƒn thá»‹: "No running jobs."
- Cáº§n deploy láº¡i jobs (xem pháº§n Deploy Jobs)

---

## ğŸ§ª Testing Commands (Windows)

### Send Test Transactions

```powershell
# BÆ°á»›c 1: Thiáº¿t láº­p access token (láº¥y tá»« Laravel API)
# Step 1: Set access token (get from Laravel API)
$TOKEN = "your_access_token_here"

# BÆ°á»›c 2: Gá»­i 5 giao dá»‹ch test vÃ o Kafka
# Step 2: Send 5 test transactions to Kafka
1..5 | ForEach-Object {
    curl -X POST http://localhost:8000/api/kafka/transactions/sales `
      -H "Authorization: Bearer $TOKEN" `
      -H "Content-Type: application/json" `
      -d "{`"order_id`": $_}"
    Write-Host "Sent transaction $_"
    Start-Sleep -Seconds 1
}
```

**Giáº£i thÃ­ch chi tiáº¿t:**

**DÃ²ng 1:** `$TOKEN = "your_access_token_here"`
- LÆ°u access token vÃ o biáº¿n Ä‘á»ƒ xÃ¡c thá»±c API
- Token nÃ y Ä‘Æ°á»£c táº¡o khi login vÃ o Laravel backend

**DÃ²ng 2:** `1..5 | ForEach-Object { ... }`
- `1..5`: Táº¡o array tá»« 1 Ä‘áº¿n 5 (PowerShell range operator)
- `|`: Pipe operator - Ä‘Æ°a output sang lá»‡nh tiáº¿p theo
- `ForEach-Object`: Loop qua tá»«ng sá»‘ tá»« 1 Ä‘áº¿n 5
- `$_`: Biáº¿n Ä‘áº¡i diá»‡n cho item hiá»‡n táº¡i trong loop

**Lá»‡nh curl:**
- `-X POST`: HTTP method lÃ  POST
- `http://localhost:8000/api/kafka/transactions/sales`: Endpoint API
- `-H "Authorization: Bearer $TOKEN"`: Header xÃ¡c thá»±c vá»›i Bearer token
- `-H "Content-Type: application/json"`: Header chá»‰ Ä‘á»‹nh dá»¯ liá»‡u JSON
- `-d "{\"order_id\": $_}"`: Data body JSON vá»›i order_id = sá»‘ hiá»‡n táº¡i
  - Dáº¥u backtick (`) escape dáº¥u ngoáº·c kÃ©p trong PowerShell
- `Write-Host`: In thÃ´ng bÃ¡o Ä‘Ã£ gá»­i transaction thá»© máº¥y
- `Start-Sleep -Seconds 1`: Äá»£i 1 giÃ¢y giá»¯a má»—i request (trÃ¡nh spam)

---

### Check Database (Windows)

```powershell
# 1. Äáº¿m tá»•ng sá»‘ giao dá»‹ch (Count total transactions)
docker exec postgres psql -U postgres -d lensart_events `
  -c "SELECT COUNT(*) FROM sales_transactions;"

# 2. Xem 10 giao dá»‹ch má»›i nháº¥t (View latest 10 transactions)
docker exec postgres psql -U postgres -d lensart_events `
  -c "SELECT * FROM sales_transactions ORDER BY created_at DESC LIMIT 10;"

# 3. Xem top 10 sáº£n pháº©m cÃ³ doanh thu cao nháº¥t (View top 10 products by revenue)
docker exec postgres psql -U postgres -d lensart_events `
  -c "SELECT * FROM product_sales ORDER BY total_revenue DESC LIMIT 10;"

# 4. Xem tá»•ng quan doanh sá»‘ (Sales summary view)
docker exec postgres psql -U postgres -d lensart_events `
  -c "SELECT * FROM v_sales_summary;"
```

**Giáº£i thÃ­ch chi tiáº¿t tá»«ng query:**

**Query 1:** `SELECT COUNT(*) FROM sales_transactions`
- Äáº¿m tá»•ng sá»‘ records trong báº£ng `sales_transactions`
- Kiá»ƒm tra xem Flink job cÃ³ Ä‘ang xá»­ lÃ½ vÃ  lÆ°u data khÃ´ng

**Query 2:** `SELECT * FROM sales_transactions ORDER BY created_at DESC LIMIT 10`
- `SELECT *`: Láº¥y táº¥t cáº£ columns
- `FROM sales_transactions`: Tá»« báº£ng giao dá»‹ch bÃ¡n hÃ ng
- `ORDER BY created_at DESC`: Sáº¯p xáº¿p theo thá»i gian táº¡o, má»›i nháº¥t trÆ°á»›c
- `LIMIT 10`: Chá»‰ láº¥y 10 records

**Query 3:** `SELECT * FROM product_sales ORDER BY total_revenue DESC LIMIT 10`
- Láº¥y tá»« báº£ng `product_sales` (Ä‘Æ°á»£c táº¡o bá»Ÿi aggregation job)
- `ORDER BY total_revenue DESC`: Sáº¯p xáº¿p theo doanh thu giáº£m dáº§n
- Xem sáº£n pháº©m nÃ o bÃ¡n cháº¡y nháº¥t

**Query 4:** `SELECT * FROM v_sales_summary`
- `v_sales_summary`: View tá»•ng há»£p Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trong schema
- Hiá»ƒn thá»‹ thá»‘ng kÃª tá»•ng quan vá» doanh sá»‘

**Tham sá»‘ chung:**
- `-U postgres`: Username
- `-d lensart_events`: Database name
- `-c "..."`: Command - SQL query cáº§n thá»±c thi
- Dáº¥u backtick (`): Line continuation trong PowerShell

---

## ğŸ”„ Daily Operations (Windows)

### Start Everything

```powershell
# BÆ°á»›c 1: Di chuyá»ƒn vÃ o thÆ° má»¥c docker
# Step 1: Navigate to docker directory
cd data_pipeline\docker

# BÆ°á»›c 2: Khá»Ÿi Ä‘á»™ng táº¥t cáº£ services trong docker-compose.yml
# Step 2: Start all services defined in docker-compose.yml
docker-compose up -d

# BÆ°á»›c 3: Äá»£i 60 giÃ¢y Ä‘á»ƒ services khá»Ÿi Ä‘á»™ng hoÃ n táº¥t
# Step 3: Wait 60 seconds for services to fully start
Start-Sleep -Seconds 60

# BÆ°á»›c 4: Kiá»ƒm tra tráº¡ng thÃ¡i cÃ¡c services
# Step 4: Check status of all services
docker-compose ps
```

**Giáº£i thÃ­ch chi tiáº¿t:**

**Lá»‡nh:** `docker-compose up -d`
- `docker-compose`: Tool quáº£n lÃ½ multi-container Docker applications
- `up`: Táº¡o vÃ  khá»Ÿi Ä‘á»™ng containers
- `-d`: Detached mode (cháº¡y ná»n, khÃ´ng chiáº¿m terminal)
- Äá»c file `docker-compose.yml` Ä‘á»ƒ biáº¿t cáº§n start services gÃ¬
- Services bao gá»“m:
  - **Zookeeper**: Quáº£n lÃ½ Kafka cluster
  - **Kafka**: Message broker
  - **PostgreSQL**: Database lÆ°u trá»¯ káº¿t quáº£
  - **Flink JobManager**: Quáº£n lÃ½ Flink jobs
  - **Flink TaskManager**: Thá»±c thi Flink jobs

**Lá»‡nh:** `Start-Sleep -Seconds 60`
- PowerShell cmdlet táº¡m dá»«ng execution
- Äá»£i services khá»Ÿi Ä‘á»™ng Ä‘áº§y Ä‘á»§ trÆ°á»›c khi lÃ m viá»‡c tiáº¿p
- Kafka vÃ  Flink cáº§n thá»i gian Ä‘á»ƒ initialize

**Lá»‡nh:** `docker-compose ps`
- Hiá»ƒn thá»‹ status cá»§a táº¥t cáº£ containers
- Cá»™t quan trá»ng: State (Up = Ä‘ang cháº¡y, Exit = Ä‘Ã£ dá»«ng)

---

### Stop Everything

```powershell
cd data_pipeline\docker
docker-compose stop
```

---

### Restart Just Flink Jobs

```powershell
# List and cancel jobs manually
docker exec flink-jobmanager flink list -r

# Cancel jobs (use actual IDs from above)
docker exec flink-jobmanager flink cancel <JOB_ID_1>
docker exec flink-jobmanager flink cancel <JOB_ID_2>

# Redeploy (see Deploy Jobs section above)
```

---

## ğŸ“Š Monitoring Commands (Windows)

### Check Everything

```powershell
# Check Docker containers
docker ps

# Check Flink jobs
docker exec flink-jobmanager flink list

# Check tables
docker exec postgres psql -U postgres -d lensart_events -c "\dt"

# Check transaction count
docker exec postgres psql -U postgres -d lensart_events `
  -c "SELECT COUNT(*) FROM sales_transactions;"

# Check product stats count
docker exec postgres psql -U postgres -d lensart_events `
  -c "SELECT COUNT(*) FROM product_sales;"
```

---

### View Logs

```powershell
# 1. Xem logs cá»§a Flink JobManager (100 dÃ²ng cuá»‘i)
# View Flink JobManager logs (last 100 lines)
docker logs flink-jobmanager --tail 100

# 2. Xem logs cá»§a Flink TaskManager (100 dÃ²ng cuá»‘i)
# View Flink TaskManager logs (last 100 lines)
docker logs flink-taskmanager --tail 100

# 3. Xem logs cá»§a Kafka (50 dÃ²ng cuá»‘i)
# View Kafka logs (last 50 lines)
docker logs kafka --tail 50

# 4. Xem logs cá»§a PostgreSQL (50 dÃ²ng cuá»‘i)
# View PostgreSQL logs (last 50 lines)
docker logs postgres --tail 50

# 5. Theo dÃµi logs real-time (nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng)
# Follow logs in real-time (press Ctrl+C to stop)
docker logs flink-taskmanager -f
```

**Giáº£i thÃ­ch chi tiáº¿t:**

**Lá»‡nh:** `docker logs <container_name> --tail <N>`
- `docker logs`: Xem logs tá»« container
- `<container_name>`: TÃªn container cáº§n xem logs
- `--tail <N>`: Chá»‰ hiá»ƒn thá»‹ N dÃ²ng cuá»‘i cÃ¹ng
  - TrÃ¡nh bá»‹ spam quÃ¡ nhiá»u logs cÅ©

**Lá»‡nh:** `docker logs <container_name> -f`
- `-f` hoáº·c `--follow`: Follow mode (real-time streaming)
- Logs sáº½ hiá»‡n liÃªn tá»¥c khi cÃ³ events má»›i
- Giá»‘ng nhÆ° `tail -f` trÃªn Linux
- Nháº¥n `Ctrl+C` Ä‘á»ƒ thoÃ¡t

**Khi nÃ o xem logs nÃ o:**
- **JobManager logs**: 
  - Khi jobs khÃ´ng deploy Ä‘Æ°á»£c
  - Khi muá»‘n xem job status changes
  - Khi cÃ³ lá»—i vá» job management
  
- **TaskManager logs**: 
  - Khi jobs Ä‘ang cháº¡y nhÆ°ng khÃ´ng xá»­ lÃ½ data
  - Khi muá»‘n xem chi tiáº¿t processing
  - Khi debug business logic errors
  
- **Kafka logs**: 
  - Khi messages khÃ´ng Ä‘Æ°á»£c gá»­i vÃ o topics
  - Khi cÃ³ connection issues vá»›i producers/consumers
  
- **PostgreSQL logs**: 
  - Khi data khÃ´ng Ä‘Æ°á»£c lÆ°u vÃ o database
  - Khi cÃ³ SQL errors hoáº·c connection issues

---

## ğŸ› Troubleshooting (Windows)

### Reset Everything

```powershell
# Clear data
docker exec postgres psql -U postgres -d lensart_events `
  -c "TRUNCATE sales_transactions, product_sales;"

# List jobs
docker exec flink-jobmanager flink list -r

# Cancel each job manually (copy IDs from above)
docker exec flink-jobmanager flink cancel <JOB_ID>

# Restart Docker services
cd data_pipeline\docker
docker-compose restart
```

---

### Check Kafka Messages

```powershell
# Xem messages trong Kafka topic "order-created"
# View messages in Kafka topic "order-created"
docker exec kafka kafka-console-consumer.sh `
  --bootstrap-server localhost:9092 `
  --topic order-created `
  --from-beginning `
  --max-messages 10
```

**Giáº£i thÃ­ch chi tiáº¿t:**

**Lá»‡nh:** `kafka-console-consumer.sh`
- Script cá»§a Kafka Ä‘á»ƒ consume (Ä‘á»c) messages tá»« topic
- Cháº¡y trong container kafka

**CÃ¡c tham sá»‘:**
- `--bootstrap-server localhost:9092`: 
  - Äá»‹a chá»‰ Kafka broker
  - Port 9092 lÃ  port máº·c Ä‘á»‹nh cá»§a Kafka
  - `localhost` vÃ¬ Ä‘ang exec trong container kafka

- `--topic order-created`: 
  - TÃªn topic cáº§n Ä‘á»c messages
  - Topic nÃ y chá»©a events vá» orders Ä‘Æ°á»£c táº¡o

- `--from-beginning`: 
  - Äá»c tá»« message Ä‘áº§u tiÃªn trong topic
  - KhÃ´ng dÃ¹ng flag nÃ y sáº½ chá»‰ Ä‘á»c messages má»›i

- `--max-messages 10`: 
  - Chá»‰ Ä‘á»c tá»‘i Ä‘a 10 messages rá»“i dá»«ng
  - TrÃ¡nh spam quÃ¡ nhiá»u messages

**Output vÃ­ dá»¥:**
```json
{"order_id": 1, "customer_id": 123, "total": 150.50, ...}
{"order_id": 2, "customer_id": 456, "total": 299.99, ...}
...
```

**Use cases:**
- Verify ráº±ng Laravel backend Ä‘Ã£ gá»­i messages vÃ o Kafka thÃ nh cÃ´ng
- Debug format cá»§a messages
- Kiá»ƒm tra xem Flink cÃ³ consume Ä‘Æ°á»£c messages khÃ´ng

---

## ğŸ“‹ Quick Reference Card (Windows)

```powershell
# 1. Khá»Ÿi Ä‘á»™ng táº¥t cáº£ services (Start all services)
cd data_pipeline\docker
docker-compose up -d

# 2. Build Flink jobs vá»›i Maven
cd ..\flink-jobs
mvn clean package -DskipTests

# 3. Quay láº¡i thÆ° má»¥c gá»‘c (Return to root)
cd ..\..

# 4. Deploy jobs
# BÆ°á»›c 4.1: Táº¡o thÆ° má»¥c trong container
docker exec flink-jobmanager mkdir -p /opt/flink/usrlib

# BÆ°á»›c 4.2: Set JAR path vÃ  copy (thay Ä‘á»•i path theo workspace cá»§a báº¡n)
$jarPath = "D:\UIT\HK5\WebDevelopment\MyProject\LensArtEyewear\lensart_eyewear_backend\data_pipeline\flink-jobs\target\lensart-sales-pipeline-1.0.0.jar"
docker cp $jarPath flink-jobmanager:/opt/flink/usrlib/lensart-sales-pipeline-1.0.0.jar

# BÆ°á»›c 4.3: Deploy cáº£ 2 jobs
docker exec flink-jobmanager flink run -d -c com.lensart.pipeline.SalesTransactionJob /opt/flink/usrlib/lensart-sales-pipeline-1.0.0.jar
docker exec flink-jobmanager bash -c "export WINDOW_SIZE_MINUTES=5 && flink run -d -c com.lensart.pipeline.ProductSalesAggregatorJob /opt/flink/usrlib/lensart-sales-pipeline-1.0.0.jar"

# 5. Kiá»ƒm tra tráº¡ng thÃ¡i jobs (Check job status)
docker exec flink-jobmanager flink list -r

# 6. Dá»«ng táº¥t cáº£ (Stop everything)
cd data_pipeline\docker
docker-compose stop
```

---

## âš ï¸ Important Notes for Windows

1. **Use PowerShell** (not CMD) for best compatibility
2. **Backticks** (\`) for line continuation in PowerShell (not backslash)
3. **Paths** use backslashes (\\) on Windows
4. **No grep/awk** - those are Linux commands, won't work directly
5. **Docker exec** commands work the same on all platforms

---

## ğŸ¯ Common Issues on Windows

### Issue: Command not recognized

**Wrong:**
```bash
docker exec flink-jobmanager bash -c '  for job in $(flink list -r | grep ":" | awk "{print \$4}"); do    flink cancel $job  done'
```
âŒ This tries to run grep on Windows

**Right:**
```powershell
# Cancel jobs manually (see Method 1 above)
docker exec flink-jobmanager flink list -r
docker exec flink-jobmanager flink cancel <JOB_ID>
```

---

### Issue: Path not found

**Wrong:**
```bash
docker cp data_pipeline/docker/postgres/file.sql ...
```
âŒ Forward slashes might cause issues

**Right:**
```powershell
docker cp data_pipeline\docker\postgres\file.sql ...
```
âœ… Use backslashes on Windows

---

### Issue: Long commands

**Use backticks for line continuation:**
```powershell
docker exec flink-jobmanager flink run -d `
  -c com.lensart.pipeline.SalesTransactionJob `
  /opt/flink/usrlib/lensart-sales-pipeline-1.0.0.jar
```

---

### Issue: Directory not found in container

**Lá»—i:**
```
Error response from daemon: Could not find the file /opt/flink/usrlib in container flink-jobmanager
```

**NguyÃªn nhÃ¢n:**
- ThÆ° má»¥c `/opt/flink/usrlib` chÆ°a tá»“n táº¡i trong container
- Container Flink máº·c Ä‘á»‹nh khÃ´ng cÃ³ thÆ° má»¥c nÃ y

**Giáº£i phÃ¡p (QUAN TRá»ŒNG - Pháº£i lÃ m trÆ°á»›c khi copy JAR):**
```powershell
# Táº¡o thÆ° má»¥c trÆ°á»›c
docker exec flink-jobmanager mkdir -p /opt/flink/usrlib

# Sau Ä‘Ã³ má»›i copy JAR
$jarPath = "D:\UIT\HK5\WebDevelopment\MyProject\LensArtEyewear\lensart_eyewear_backend\data_pipeline\flink-jobs\target\lensart-sales-pipeline-1.0.0.jar"
docker cp $jarPath flink-jobmanager:/opt/flink/usrlib/lensart-sales-pipeline-1.0.0.jar
```

**Giáº£i thÃ­ch:**
- `mkdir -p`: Táº¡o thÆ° má»¥c (vÃ  cÃ¡c thÆ° má»¥c cha náº¿u cáº§n)
- `-p`: KhÃ´ng bÃ¡o lá»—i náº¿u thÆ° má»¥c Ä‘Ã£ tá»“n táº¡i
- Pháº£i cháº¡y lá»‡nh nÃ y Má»˜T Láº¦N trÆ°á»›c khi deploy

---

### Issue: Docker tar writer error / Path resolution error

**Lá»—i:**
```
Error: Can't add file to tar: io: read/write on closed pipe
Error: error while creating mount source path '/run/desktop/mnt/host/d/UIT/HK5/Web Development/...'
```

**NguyÃªn nhÃ¢n:**
- Docker Desktop trÃªn Windows Ä‘Ã´i khi nháº§m láº«n Ä‘Æ°á»ng dáº«n
- ÄÆ°á»ng dáº«n tÆ°Æ¡ng Ä‘á»‘i bá»‹ resolve sai thÃ nh path cÃ³ khoáº£ng tráº¯ng
- Docker cá»‘ gáº¯ng mount path khÃ´ng Ä‘Ãºng

**Giáº£i phÃ¡p 1: Sá»­ dá»¥ng Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i (Khuyáº¿n nghá»‹):**
```powershell
# Táº¡o thÆ° má»¥c trÆ°á»›c (QUAN TRá»ŒNG!)
docker exec flink-jobmanager mkdir -p /opt/flink/usrlib

# DÃ¹ng Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i
$jarPath = "D:\UIT\HK5\WebDevelopment\MyProject\LensArtEyewear\lensart_eyewear_backend\data_pipeline\flink-jobs\target\lensart-sales-pipeline-1.0.0.jar"
docker cp $jarPath flink-jobmanager:/opt/flink/usrlib/lensart-sales-pipeline-1.0.0.jar
```

**Giáº£i phÃ¡p 2: Navigate vÃ o thÆ° má»¥c trÆ°á»›c:**
```powershell
# Táº¡o thÆ° má»¥c trÆ°á»›c
docker exec flink-jobmanager mkdir -p /opt/flink/usrlib

# Di chuyá»ƒn vÃ o thÆ° má»¥c chá»©a file, sau Ä‘Ã³ copy trá»±c tiáº¿p
cd data_pipeline\flink-jobs\target
docker cp lensart-sales-pipeline-1.0.0.jar flink-jobmanager:/opt/flink/usrlib/
cd ..\..\..
```

**Kiá»ƒm tra file Ä‘Ã£ copy thÃ nh cÃ´ng:**
```powershell
# XÃ¡c nháº­n file Ä‘Ã£ cÃ³ trong container
docker exec flink-jobmanager ls -lh /opt/flink/usrlib/

# Káº¿t quáº£ mong Ä‘á»£i:
# -rw-r--r-- 1 flink flink 6.8M Nov 22 16:00 lensart-sales-pipeline-1.0.0.jar
```

**Ã nghÄ©a:**
- `mkdir -p`: Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
- `ls -lh`: List files vá»›i format dá»… Ä‘á»c (human-readable) Ä‘á»ƒ xÃ¡c nháº­n
- File size khoáº£ng 6.8MB lÃ  Ä‘Ãºng

**Náº¿u tháº¥y "Successfully copied" nhÆ°ng váº«n cÃ³ error:**
- Äá»«ng lo! File Ä‘Ã£ Ä‘Æ°á»£c copy thÃ nh cÃ´ng
- Lá»—i tar writer chá»‰ lÃ  warning cá»§a Docker Desktop trÃªn Windows
- Tiáº¿p tá»¥c deploy jobs bÃ¬nh thÆ°á»ng:

```powershell
# Deploy cáº£ 2 jobs
docker exec flink-jobmanager flink run -d -c com.lensart.pipeline.SalesTransactionJob /opt/flink/usrlib/lensart-sales-pipeline-1.0.0.jar
docker exec flink-jobmanager bash -c "export WINDOW_SIZE_MINUTES=5 && flink run -d -c com.lensart.pipeline.ProductSalesAggregatorJob /opt/flink/usrlib/lensart-sales-pipeline-1.0.0.jar"

# XÃ¡c nháº­n jobs Ä‘Ã£ cháº¡y
docker exec flink-jobmanager flink list -r
```

---

**Version:** 1.0.0  
**Platform:** Windows 10/11 PowerShell  
**Last Updated:** 22/11/2024  
**Status:** âœ… Tested on Windows

